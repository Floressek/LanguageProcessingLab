{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "# Fine-tuning a Pretrained Model for sentiment analysis",
   "id": "d26037aadad0840b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing necessary libraries and data\n",
   "id": "15d09dfe44d655d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:17:28.523157Z",
     "start_time": "2025-11-14T17:17:23.902525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install datasets evaluate transformers[sentencepiece]\n",
    "!pip install ipywidgets\n",
    "!pip install torch\n",
    "!pip install transformers[torch]\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install scikit-learn"
   ],
   "id": "efdad8b2b5ab54d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: evaluate in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (0.4.6)\n",
      "Requirement already satisfied: transformers[sentencepiece] in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from datasets) (2.3.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from transformers[sentencepiece]) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from transformers[sentencepiece]) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from transformers[sentencepiece]) (0.6.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from transformers[sentencepiece]) (0.2.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from transformers[sentencepiece]) (6.33.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (8.1.8)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from ipywidgets) (9.7.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: colorama>=0.4.4 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator>=4.3.2 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: torch in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: transformers[torch] in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from transformers[torch]) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from transformers[torch]) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from transformers[torch]) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from transformers[torch]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from transformers[torch]) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from transformers[torch]) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from transformers[torch]) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from transformers[torch]) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from transformers[torch]) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.2 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from transformers[torch]) (2.7.1+cu118)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from transformers[torch]) (1.11.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (4.15.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (7.1.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torch>=2.2->transformers[torch]) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torch>=2.2->transformers[torch]) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torch>=2.2->transformers[torch]) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torch>=2.2->transformers[torch]) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.2->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from jinja2->torch>=2.2->transformers[torch]) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from requests->transformers[torch]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from requests->transformers[torch]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from requests->transformers[torch]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from requests->transformers[torch]) (2025.11.12)\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (0.22.1+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torchvision) (2.3.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\szyme\\pycharmprojects\\languageprocessinglab\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T18:39:53.784036Z",
     "start_time": "2025-11-14T18:39:53.693711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!nvidia-smi\n",
    "import torch\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"WARNING: Training on CPU will be very slow!\")"
   ],
   "id": "f6d0e86c409e9a9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 14 19:39:53 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 581.42                 Driver Version: 581.42         CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   43C    P5             25W /  215W |    4740MiB /  12282MiB |     21%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1416    C+G   C:\\Windows\\System32\\dwm.exe           N/A      |\n",
      "|    0   N/A  N/A            2332    C+G   ....0.3595.53\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A            2736    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A            5108    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A            7252    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           11540    C+G   ...4__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A           12376    C+G   ...l\\Programs\\Opera GX\\opera.exe      N/A      |\n",
      "|    0   N/A  N/A           12668    C+G   ...GABYTE\\Control Center\\GCC.exe      N/A      |\n",
      "|    0   N/A  N/A           14740    C+G   ...lus\\logioptionsplus_agent.exe      N/A      |\n",
      "|    0   N/A  N/A           14780    C+G   ...D\\CNext\\CNext\\AMDRSSrcExt.exe      N/A      |\n",
      "|    0   N/A  N/A           15060    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           15140    C+G   ...indows\\System32\\ShellHost.exe      N/A      |\n",
      "|    0   N/A  N/A           16828    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           16836    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           19100    C+G   ....0.3595.53\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           19252    C+G   ...64__zpdnekdrzrea0\\Spotify.exe      N/A      |\n",
      "|    0   N/A  N/A           20520    C+G   ...Next\\CNext\\RadeonSoftware.exe      N/A      |\n",
      "|    0   N/A  N/A           20576    C+G   ...roadcast\\NVIDIA Broadcast.exe      N/A      |\n",
      "|    0   N/A  N/A           21188    C+G   ...cord\\app-1.0.9214\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A           22276    C+G   ...lpaper_engine\\wallpaper64.exe      N/A      |\n",
      "|    0   N/A  N/A           23288    C+G   ...l\\Programs\\Opera GX\\opera.exe      N/A      |\n",
      "|    0   N/A  N/A           23576    C+G   ...__8yrtsj140pw4g\\app\\Slack.exe      N/A      |\n",
      "|    0   N/A  N/A           23656    C+G   ...zcv7bpp5a\\Raycast\\Raycast.exe      N/A      |\n",
      "|    0   N/A  N/A           24616    C+G   ...__8yrtsj140pw4g\\app\\Slack.exe      N/A      |\n",
      "|    0   N/A  N/A           24772    C+G   ....0.3595.53\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           28520    C+G   ...4__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A           29960    C+G   ....0.3595.53\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           31076    C+G   ...0_x64__8wekyb3d8bbwe\\Todo.exe      N/A      |\n",
      "|    0   N/A  N/A           31724      C   ...gLab\\.venv\\Scripts\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           33752    C+G   ...harm 2\\jbr\\bin\\cef_server.exe      N/A      |\n",
      "|    0   N/A  N/A           35756    C+G   ...Claude\\app-1.0.332\\claude.exe      N/A      |\n",
      "|    0   N/A  N/A           36000    C+G   ...em32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A           36392    C+G   C:\\Windows\\System32\\Taskmgr.exe       N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "CUDA available: True\n",
      "Device: NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:21:55.196741Z",
     "start_time": "2025-11-14T20:21:52.456375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = Path().resolve()\n",
    "\n",
    "amazon_mobile_reviews_url = \"https://eduds.blob.core.windows.net/nlp/Amazon_Unlocked_Mobile.csv.zip\"\n",
    "filename = \"data/Amazon_Unlocked_Mobile.csv.zip\"\n",
    "data_dir = base_dir / \"data\"\n",
    "\n",
    "zip_path = data_dir / \"Amazon_Unlocked_Mobile.csv.zip\"\n",
    "csv_path = data_dir / \"Amazon_Unlocked_Mobile.csv\"\n",
    "\n",
    "urlretrieve(amazon_mobile_reviews_url, filename)\n",
    "\n",
    "with zipfile.ZipFile(zip_path) as zfile:\n",
    "    zfile.extractall(data_dir)\n",
    "\n",
    "df = pd.read_csv(csv_path)"
   ],
   "id": "af23e8e3d03e3bfb",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:21:56.503693Z",
     "start_time": "2025-11-14T20:21:56.440111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.info()\n",
    "df.describe()\n",
    "df.head()"
   ],
   "id": "27b0bab46de0d18d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 413840 entries, 0 to 413839\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Product Name  413840 non-null  object \n",
      " 1   Brand Name    348669 non-null  object \n",
      " 2   Price         407907 non-null  float64\n",
      " 3   Rating        413840 non-null  int64  \n",
      " 4   Reviews       413770 non-null  object \n",
      " 5   Review Votes  401544 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 18.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \n",
       "0       5  I feel so LUCKY to have found this used (phone...           1.0  \n",
       "1       4  nice phone, nice up grade from my pantach revu...           0.0  \n",
       "2       5                                       Very pleased           0.0  \n",
       "3       4  It works good but it goes slow sometimes but i...           0.0  \n",
       "4       4  Great phone to replace my lost phone. The only...           0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CONFIGURATION\n",
   "id": "a44e589066e2e256"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T18:46:29.881682Z",
     "start_time": "2025-11-14T18:46:29.879491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA_URL = \"https://eduds.blob.core.windows.net/nlp/Amazon_Unlocked_Mobile.csv.zip\"\n",
    "DATA_FILE = \"data/Amazon_Unlocked_Mobile.csv\"\n",
    "MODEL_CHECKPOINT = \"distilbert-base-uncased\"\n",
    "REPO_NAME = \"Floressek/sentiment_classification_from_distillbert\"\n",
    "HUGGING_FACE_TOKEN = \"here input your token\"\n",
    "\n",
    "MAX_REVIEW_LENGTH = 128\n",
    "TEST_SIZE = 0.3\n",
    "BATCH_SIZE = 48\n",
    "BATCH_SIZE_TOKEN = 1000\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 2\n",
    "WEIGHT_DECAY = 0.01\n",
    "SEED = 100"
   ],
   "id": "2cf90b8ba07d0a63",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data cleaning\n",
   "id": "fbce9d6f95c91c27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T18:46:31.582547Z",
     "start_time": "2025-11-14T18:46:31.574356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df.drop(columns=[\"Brand Name\", \"Price\", \"Review Votes\", \"Product Name\"])\n",
    "df.head()"
   ],
   "id": "d6daa3969babb120",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Rating                                            Reviews\n",
       "0       5  I feel so LUCKY to have found this used (phone...\n",
       "1       4  nice phone, nice up grade from my pantach revu...\n",
       "2       5                                       Very pleased\n",
       "3       4  It works good but it goes slow sometimes but i...\n",
       "4       4  Great phone to replace my lost phone. The only..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T18:46:34.926211Z",
     "start_time": "2025-11-14T18:46:33.614096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "dataset = dataset.filter(\n",
    "    lambda x: (\n",
    "            x[\"Reviews\"] is not None\n",
    "            and len(x[\"Reviews\"].split()) < MAX_REVIEW_LENGTH\n",
    "            and x[\"Rating\"] in [1, 5]  # skrajnosci do binary classification\n",
    "    )\n",
    ")\n",
    "\n",
    "dataset_split = dataset.train_test_split(test_size=TEST_SIZE, seed=SEED)"
   ],
   "id": "40a44a79b98aa996",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/413840 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5023c01162324b84afb19ec45a970c56"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tokenization",
   "id": "f1cb6bd3ccecc50d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T18:46:37.851802Z",
     "start_time": "2025-11-14T18:46:37.100084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import DatasetDict\n",
    "from typing import Any\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
    "\n",
    "\n",
    "# zostawiamy inputs id z tokenizacji i attention mask dla padding/tresc oraz labels\n",
    "def tokenize_and_label(dataset: DatasetDict, tokenizer: Any):\n",
    "    def tokenize_function(example):\n",
    "        return tokenizer(example[\"Reviews\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "    def convert_to_binary_label(example):\n",
    "        return {'label': [0 if r == 1 else 1 for r in example['Rating']]}\n",
    "\n",
    "    tokenized = dataset.map(tokenize_function, batched=True, batch_size=BATCH_SIZE_TOKEN)\n",
    "    tokenized = tokenized.map(convert_to_binary_label, batched=True, batch_size=BATCH_SIZE_TOKEN)\n",
    "    tokenized = tokenized.remove_columns([\"Reviews\", \"Rating\"])\n",
    "\n",
    "    return tokenized"
   ],
   "id": "18c877bae841c93e",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T18:46:41.756880Z",
     "start_time": "2025-11-14T18:46:41.754675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from evaluate import load\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred) -> dict:\n",
    "    accuracy_metric = load(\"accuracy\")\n",
    "    f1_metric = load(\"f1\")\n",
    "\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}"
   ],
   "id": "763efe8d9ac72643",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Huggingface - logging and model loading\n",
   "id": "b73061c3bcedc4a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T18:46:44.096470Z",
     "start_time": "2025-11-14T18:46:43.924416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "token = HUGGING_FACE_TOKEN\n",
    "\n",
    "if token:\n",
    "    login(token=HUGGING_FACE_TOKEN)\n",
    "else:\n",
    "    login()"
   ],
   "id": "b439612b50fed578",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train and fine-tuning the model\n",
   "id": "9560b042d0525b99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T19:29:10.301060Z",
     "start_time": "2025-11-14T18:46:45.568724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "def train_model(tokenized_datasets: DatasetDict, tokenizer) -> Trainer:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_CHECKPOINT,\n",
    "        num_labels=2,\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=REPO_NAME,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        num_train_epochs=NUM_EPOCHS,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        save_strategy=\"epoch\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        push_to_hub=True,\n",
    "        remove_unused_columns=False,\n",
    "        logging_steps=100,\n",
    "        fp16=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets['train'],\n",
    "        eval_dataset=tokenized_datasets['test'],\n",
    "        processing_class=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    return trainer\n",
    "\n",
    "\n",
    "print(f\"Train size: {len(dataset_split['train'])}\")\n",
    "print(f\"Test size: {len(dataset_split['test'])}\")\n",
    "\n",
    "tokenized_datasets = tokenize_and_label(dataset_split, tokenizer)\n",
    "\n",
    "trainer = train_model(tokenized_datasets, tokenizer)"
   ],
   "id": "f2baddc39582ea90",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 196375\n",
      "Test size: 84162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/196375 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9eca0885f7e941e9ba0225ecab5226b5"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/84162 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46e17d5252ff4edba4613665ce78610f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/196375 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b0899afc630842dd9c6de08b7d186a3b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/84162 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "669f11f90f5d4ac19919c0ae3772bf7b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8184' max='8184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8184/8184 41:33, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.040534</td>\n",
       "      <td>0.989152</td>\n",
       "      <td>0.992839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.035284</td>\n",
       "      <td>0.991718</td>\n",
       "      <td>0.994545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "5232456d49be4c01fb108dc77e31f262"
     }
    },
    {
     "data": {
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ea920f26713434d9390bbe9cfa3a896"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b661d468c9394cf7a2f3e161a223adf1"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e755ba88b1e4457b8bab9944d4b1412f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing the newly fine-tuned model\n",
   "id": "195c0e81bf298c1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T19:56:16.772843Z",
     "start_time": "2025-11-14T19:56:16.769490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "def create_classifier(model_path=f\"./{REPO_NAME}\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "    return pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "def test_classifier(classifier) -> None:\n",
    "    examples = [\n",
    "        \"Shame. I wish I hadn't buy it.\",\n",
    "        \"Great handset!\",\n",
    "        \"Terrible product, waste of money\",\n",
    "        \"Best phone ever, highly recommend!\"\n",
    "    ]\n",
    "\n",
    "    for text in examples:\n",
    "        result = classifier(text)\n",
    "        print(f\"Text: {text}\")\n",
    "        print(f\"Result: {result}\\n\")\n"
   ],
   "id": "c1ce352b5ebe328c",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Eval metrics",
   "id": "d4c5787afb9e6ae7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:06:29.136185Z",
     "start_time": "2025-11-14T20:03:59.964777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, precision_recall_curve, auc\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "model_path = f\"./{REPO_NAME}\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "print(model)\n",
    "\n",
    "preds = trainer.predict(tokenized_datasets[\"test\"])\n",
    "logits = preds.predictions\n",
    "y_true = preds.label_ids\n",
    "y_pred = np.argmax(logits, axis=-1)\n",
    "probs = torch.softmax(torch.from_numpy(logits), dim=-1).numpy()[:, 1]\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "roc_auc = roc_auc_score(y_true, probs)\n",
    "prec_curve, rec_curve, _ = precision_recall_curve(y_true, probs)\n",
    "pr_auc = auc(rec_curve, prec_curve)\n",
    "report = classification_report(y_true, y_pred, digits=4)\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)\n",
    "print(f\"TP={tp} FP={fp} TN={tn} FN={fn}\")\n",
    "print(f\"ROC-AUC={roc_auc:.4f} PR-AUC={pr_auc:.4f}\")\n",
    "print(report)\n"
   ],
   "id": "e3308ae685c70928",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture: DistilBertForSequenceClassification\n",
      "DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"dtype\": \"float32\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Total params: 66,955,010\n",
      "Trainable params: 66,955,010\n",
      "Confusion matrix:\n",
      "[[19922   352]\n",
      " [  345 63543]]\n",
      "TP=63543 FP=352 TN=19922 FN=345\n",
      "ROC-AUC=0.9983 PR-AUC=0.9994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9830    0.9826    0.9828     20274\n",
      "           1     0.9945    0.9946    0.9945     63888\n",
      "\n",
      "    accuracy                         0.9917     84162\n",
      "   macro avg     0.9887    0.9886    0.9887     84162\n",
      "weighted avg     0.9917    0.9917    0.9917     84162\n",
      "\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Testing the model with text samples",
   "id": "6fcdad5dc49bc568"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T19:59:26.564660Z",
     "start_time": "2025-11-14T19:59:26.258924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pomijam bo mialem w trakcie uczenia eval wlaczony\n",
    "# eval_results = trainer.evaluate()\n",
    "# print(f\"Evaluation results: {eval_results}\")\n",
    "\n",
    "print(\"Testing the fine-tuned model:\")\n",
    "classifier = create_classifier()\n",
    "test_classifier(classifier)"
   ],
   "id": "993ea8f31d059b8d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the fine-tuned model:\n",
      "Text: Shame. I wish I hadn't buy it.\n",
      "Result: [{'label': 'LABEL_0', 'score': 0.9975292086601257}]\n",
      "\n",
      "Text: Great handset!\n",
      "Result: [{'label': 'LABEL_1', 'score': 0.9996094107627869}]\n",
      "\n",
      "Text: Terrible product, waste of money\n",
      "Result: [{'label': 'LABEL_0', 'score': 0.998723566532135}]\n",
      "\n",
      "Text: Best phone ever, highly recommend!\n",
      "Result: [{'label': 'LABEL_1', 'score': 0.9996873140335083}]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 58
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
